---
layout: default
title: softmax
---
so what is softmax? 
softmax is an activation function often used in the final layer of a multi class neural network. it basically tell us given an example what is the probability of it belonging to each class.that is P(y=j|x)

so for instance if we have a dog, a cat and a cow classes and we give it an example of a cat it will give us a probabilty like this [.1,.6,.3]. which is intutive for us, it's 60% sure it's a cat, 30% sure it's a cow and 10% sure it's a dog. which is okay, maybe the cat is alittle fat, no judging.

now that we have established that it's output is intuitive for us to understand and that it's mathematically convient? let's deep dive of how it works
Softmax is defined as:

$$\text{Softmax}(x_{i}) = \frac{e^{z_i}}{\sum_j e^{Z_j}}$$



remember that typically in a layer we compute the linear part $$Z_{L}$$ then we apply the activation function.
